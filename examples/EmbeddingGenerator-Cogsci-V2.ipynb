{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Sentences with TreeRNNs\n",
    "\n",
    "This notebook goes through a minimal example of encoding one sentence into a distributed representation using a TreeRNN, and the using this distributed representation to generate another sentence using a different TreeRNN in reverse. To start, we'll do some data cleaning to make sure we have a good set of sentence pairs to train on. The main goal here is to remove sentences with mispelled words and oddities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant \n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from pysem.corpora import SNLI\n",
    "from pysem.networks import DependencyNetwork\n",
    "from pysem.generatives import EmbeddingGenerator\n",
    "\n",
    "checker = enchant.Dict('en_US')\n",
    "TrainingPair = namedtuple('TrainingPair', ['sentence1', 'sentence2', 'label'])\n",
    "\n",
    "snli = SNLI('/home/pblouw/snli_1.0/')\n",
    "snli.load_xy_pairs()\n",
    "\n",
    "def repair(sen):\n",
    "    tokens = DependencyNetwork.parser(sen)\n",
    "    if len(tokens) > 15:\n",
    "        return None\n",
    "    for token in tokens:\n",
    "        if not checker.check(token.text):\n",
    "            return None\n",
    "    return sen\n",
    "\n",
    "def clean_data(data):\n",
    "    clean = []\n",
    "    for item in data:\n",
    "        \n",
    "        s1 = repair(item.sentence1)\n",
    "        s2 = repair(item.sentence2)\n",
    "        if s1 == None or s2 == None:\n",
    "            continue\n",
    "        else:\n",
    "            clean.append(TrainingPair(s1, s2, item.label))\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_dev = clean_data(snli.dev_data)\n",
    "clean_train = clean_data(snli.train_data)\n",
    "clean_test = clean_data(snli.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955\n",
      "4839\n",
      "306651\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_dev))\n",
    "print(len(clean_test))\n",
    "print(len(clean_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build a vocab from the set of cleaned sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    vocab = set()\n",
    "    for item in data:\n",
    "        s1 = item.sentence1\n",
    "        s2 = item.sentence2\n",
    "        \n",
    "        t1 = DependencyNetwork.parser(s1)\n",
    "        t2 = DependencyNetwork.parser(s2)\n",
    "        \n",
    "        for t in t1:\n",
    "            if t.text not in vocab:\n",
    "                vocab.add(t.text)\n",
    "        for t in t2:\n",
    "            if t.text not in vocab:\n",
    "                vocab.add(t.text)\n",
    "\n",
    "    return sorted(list(vocab))\n",
    "\n",
    "data = clean_dev + clean_test + clean_train\n",
    "vocab = build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22555\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can collect all of the sentence pairs standing in entailment relations to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106288\n",
      "1666\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "train_data = [d for d in clean_train if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "test_data = [d for d in clean_test if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "dev_data = [d for d in clean_dev if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration  0\n",
      "On iteration  1\n",
      "On iteration  2\n",
      "On iteration  3\n",
      "On iteration  4\n",
      "On iteration  5\n",
      "On iteration  6\n",
      "On iteration  7\n",
      "On iteration  8\n",
      "On iteration  9\n",
      "On iteration  10\n",
      "On iteration  11\n",
      "On iteration  12\n",
      "On iteration  13\n",
      "On iteration  14\n",
      "On iteration  15\n",
      "On iteration  16\n",
      "On iteration  17\n",
      "On iteration  18\n",
      "On iteration  19\n",
      "On iteration  20\n",
      "On iteration  21\n",
      "On iteration  22\n",
      "On iteration  23\n",
      "On iteration  24\n",
      "On iteration  25\n",
      "On iteration  26\n",
      "On iteration  27\n",
      "On iteration  28\n",
      "On iteration  29\n",
      "On iteration  30\n",
      "On iteration  31\n",
      "On iteration  32\n",
      "On iteration  33\n",
      "On iteration  34\n",
      "On iteration  35\n",
      "On iteration  36\n",
      "On iteration  37\n",
      "On iteration  38\n",
      "On iteration  39\n",
      "On iteration  40\n",
      "On iteration  41\n",
      "On iteration  42\n",
      "On iteration  43\n",
      "On iteration  44\n",
      "On iteration  45\n",
      "On iteration  46\n",
      "On iteration  47\n",
      "On iteration  48\n",
      "On iteration  49\n",
      "On iteration  50\n",
      "On iteration  51\n",
      "On iteration  52\n",
      "On iteration  53\n",
      "On iteration  54\n",
      "On iteration  55\n",
      "On iteration  56\n",
      "On iteration  57\n",
      "On iteration  58\n",
      "On iteration  59\n",
      "On iteration  60\n",
      "On iteration  61\n",
      "On iteration  62\n",
      "On iteration  63\n",
      "On iteration  64\n",
      "On iteration  65\n",
      "On iteration  66\n",
      "On iteration  67\n",
      "On iteration  68\n",
      "On iteration  69\n",
      "On iteration  70\n",
      "On iteration  71\n",
      "On iteration  72\n",
      "On iteration  73\n",
      "On iteration  74\n",
      "On iteration  75\n",
      "On iteration  76\n",
      "On iteration  77\n",
      "On iteration  78\n",
      "On iteration  79\n",
      "On iteration  80\n",
      "On iteration  81\n",
      "On iteration  82\n",
      "On iteration  83\n",
      "On iteration  84\n",
      "On iteration  85\n",
      "On iteration  86\n",
      "On iteration  87\n",
      "On iteration  88\n",
      "On iteration  89\n",
      "On iteration  90\n",
      "On iteration  91\n",
      "On iteration  92\n",
      "On iteration  93\n",
      "On iteration  94\n",
      "On iteration  95\n",
      "On iteration  96\n",
      "On iteration  97\n",
      "On iteration  98\n",
      "On iteration  99\n"
     ]
    }
   ],
   "source": [
    "dim = 300\n",
    "iters = 100\n",
    "rate = 0.0006\n",
    "batchsize = 10000\n",
    "\n",
    "vectors = 'w2v_embeddings.pickle'\n",
    "\n",
    "with open('w2v_dep_vocabs.pickle', 'rb') as pfile:\n",
    "    subvocabs = pickle.load(pfile)\n",
    "\n",
    "encoder = DependencyNetwork(dim=dim, vocab=vocab, pretrained=vectors)\n",
    "decoder = EmbeddingGenerator(dim=dim, subvocabs=subvocabs, vectors=vectors)\n",
    "\n",
    "for _ in range(iters):\n",
    "    print('On iteration ', _)\n",
    "    if _ == 60:\n",
    "        rate = rate / 2.0\n",
    "    if _ == 75:\n",
    "        rate = rate / 2.0\n",
    "    if _ == 90:\n",
    "        rate = rate / 2.0\n",
    "    \n",
    "    batch = random.sample(train_data, batchsize)\n",
    "    for sample in batch:\n",
    "        s1 = sample.sentence1\n",
    "        s2 = sample.sentence2\n",
    "\n",
    "        encoder.forward_pass(s1)        \n",
    "        decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "        decoder.backward_pass(rate=rate)\n",
    "        encoder.backward_pass(decoder.pass_grad, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Entailment Generation Examples\n",
    "\n",
    "This small amount of data probably isn't enough to generalize outside of the training set, so we'll first check how well the learned decoder is able to generate the entailments it has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A group of Asians and one Anglo stand outside bundled in winter clothing.\n",
      "Predicted Entailment:  group are are outside .\n",
      "Actual Entailment:  people are standing outside .\n",
      "\n",
      "Sentence:  A man with a hat is playing the guitar.\n",
      "Predicted Entailment:  playing playing a guitar .\n",
      "Actual Entailment:  man playing a guitar .\n",
      "\n",
      "Sentence:  Here is a picture of a band performing living at a concert.\n",
      "Predicted Entailment:  a is performing a concert concert in concert of many fans .\n",
      "Actual Entailment:  a band performing a concert live in front of many fans .\n",
      "\n",
      "Sentence:  A lady holds a little girl who is trying to catch bubbles.\n",
      "Predicted Entailment:  a girl is playing .\n",
      "Actual Entailment:  a girl is playing .\n",
      "\n",
      "Sentence:  Man in a helmet riding a dirt bike covered with mud.\n",
      "Predicted Entailment:  a man is riding with a bike .\n",
      "Actual Entailment:  a man is traveling on a bike .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_trees = [d for d in dev_data if 5 < len(d.sentence2.split()) < 10]\n",
    "batch = random.sample(train_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate entailments using randomly chosen trees for the decoding network structure. This doesn't work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Several people wait to checkout inside a store with a warehouse looking ceiling.\n",
      "Predicted Entailment:  several people are are inside a store\n",
      "Actual Entailment:  many people are waiting in a store\n",
      "Random Tree Entailment:  the people are inside a store .\n",
      "\n",
      "Sentence:  A person walking uphill from a construction zone.\n",
      "Predicted Entailment:  a person walking in a construction zone .\n",
      "Actual Entailment:  a hill is near a construction site .\n",
      "Random Tree Entailment:  two person walking in a zone\n",
      "\n",
      "Sentence:  Four motorcycles are racing on a dirt track.\n",
      "Predicted Entailment:  four motorcycles are racing\n",
      "Actual Entailment:  four motorcycles are racing\n",
      "Random Tree Entailment:  the motorcycles racing on a track .\n",
      "\n",
      "Sentence:  An Asian girl writes down something on a notepad in her lap.\n",
      "Predicted Entailment:  an old girl is is .\n",
      "Actual Entailment:  an asian girl is sitting .\n",
      "Random Tree Entailment:  one girl is is on a writing\n",
      "\n",
      "Sentence:  School kids all in blue backpacks.\n",
      "Predicted Entailment:  many kids all kids blue school backpacks .\n",
      "Actual Entailment:  young students all carry blue book bags .\n",
      "Random Tree Entailment:  kids are kids in some backpack backpacks .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = random.sample(dev_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    \n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "\n",
    "    decoder.forward_pass(randsen.sentence2, encoder.get_root_embedding())\n",
    "    alternate = [node.pword for node in decoder.tree]\n",
    "    print('Random Tree Entailment: ', ' '.join(alternate))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Entailment Chains (i.e. Inferential Roles)\n",
    "\n",
    "We can also generate entailment chains by re-encoding a generated sentence, and then generating new sentence from the subsequent encoding. This is kind of neat because it allows us to distill what the model has learned in a network of inferential relationships between sentences. Philosophers sometimes argue that the meaning of sentences is determined by it's role or location in such a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A black dog with a blue collar is jumping into the water.\n",
      "Predicted Entailment:  a dog is in the water .\n",
      "Next Prediction:  a dog is wet .\n",
      "\n",
      "Sentence:  A black dog with a blue collar is jumping into the water.\n",
      "Predicted Entailment:  a his s dog is wet .\n",
      "Next Prediction:  a dog is .\n",
      "\n",
      "Sentence:  Two police officers are sitting on motorcycles in the road.\n",
      "Predicted Entailment:  two officers are on their road .\n",
      "Next Prediction:  the officers are same outdoors .\n",
      "\n",
      "Sentence:  Five people are playing in a gymnasium.\n",
      "Predicted Entailment:  the people are are together .\n",
      "Next Prediction:  the people are together .\n",
      "\n",
      "Sentence:  A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.\n",
      "Predicted Entailment:  a woman is makeup .\n",
      "Next Prediction:  a female woman makeup physical makeup .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'A black dog with a blue collar is jumping into the water.'\n",
    "s2 = 'A dog chases in a field.'\n",
    "s3 = 'A frog is cold.'\n",
    "\n",
    "def predict(encoder, decoder, s1, s2, s3):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "\n",
    "    encoder.forward_pass(' '.join(predicted))\n",
    "    decoder.forward_pass(s3, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Next Prediction: ', ' '.join(predicted))\n",
    "    print('')\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "    \n",
    "s1 = 'A black dog with a blue collar is jumping into the water.'\n",
    "s2 = 'Some dog\\'s collar is blue.'\n",
    "s3 = 'The man sleeps.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Two police officers are sitting on motorcycles in the road.'\n",
    "s2 = 'Two policemen sit on their bikes.'\n",
    "s3 = 'The men have big guns.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Five people are playing in a gymnasium.'\n",
    "s2 = 'Some people are competing indoors.'\n",
    "s3 = 'Some people are inside.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.'\n",
    "s2 = 'The woman applies eyeliner.'\n",
    "s3 = 'The red woman applies green eyeliner.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  water\n",
      "Predicted Entailment:  a shirtless man is in the blue water .\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  blue\n",
      "Predicted Entailment:  a blue man is in the blue boat .\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  fishing\n",
      "Predicted Entailment:  a shirtless man fishing in the blue water .\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  sleep\n",
      "Predicted Entailment:  a shirtless man sleeps in the blue water .\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  boat\n",
      "Predicted Entailment:  a shirtless boat boat in the blue boat .\n",
      "\n",
      "Sentence:  A mother and daughter walk along the side of a bridge.\n",
      "Conditioning Context:  How many people are walking?\n",
      "Predicted Entailment:  two people are walking .\n",
      "\n",
      "Sentence:  A mother and daughter walk along the side of a bridge.\n",
      "Conditioning Context:  Are the mother and daughter walking?\n",
      "Predicted Entailment:  the mother and daughter walking outdoors .\n",
      "\n",
      "Sentence:  A mother and daughter walk along the side of a bridge.\n",
      "Conditioning Context:  What is the bridge over?\n",
      "Predicted Entailment:  a people are on the bridge .\n"
     ]
    }
   ],
   "source": [
    "def condition(encoder, decoder, s1, s2, cond):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding() + cond)\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "      \n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'water'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "        \n",
    "        \n",
    "        \n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'blue'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "\n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'fishing'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "        \n",
    "        \n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'sleep'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'boat'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "\n",
    "s1 = 'A mother and daughter walk along the side of a bridge.'\n",
    "s2 = 'Two people are walking.'\n",
    "cond_sen = 'How many people are walking?'\n",
    "\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "s1 = 'A mother and daughter walk along the side of a bridge.'\n",
    "s2 = 'The mother and daughter walk together.'\n",
    "cond_sen = 'Are the mother and daughter walking?'\n",
    "\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "s1 = 'A mother and daughter walk along the side of a bridge.'\n",
    "s2 = 'The bridge is over a river.'\n",
    "cond_sen = 'What is the bridge over?'\n",
    "\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "condition(encoder, decoder, s1, s2, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Substitional Analysis\n",
    "\n",
    "Finally, it is also possible to examine the effect a given word or phrase has on entailment generation via substitutions. Essentially, this involves looking at the difference made to the most likely entailment when a given word or phrase in the input sentence is replaced with another word or phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are on a raft .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are together .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are together on a raft .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are on a inflatable raft .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  several kids are on a raft .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  several kids are all on a raft .\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are on a inflatable raft .\n",
      "\n",
      "Sentence:  Several kids are all on a raft.\n",
      "Predicted Entailment:  the kids are on a several raft .\n",
      "\n",
      "Sentence:  Several kids are all on a raft.\n",
      "Predicted Entailment:  kids are on one raft .\n",
      "\n",
      "Sentence:  Several kids are all on a raft.\n",
      "Predicted Entailment:  some are riding on a raft .\n",
      "\n",
      "Sentence:  Several kids are all on a raft.\n",
      "Predicted Entailment:  the kids are on a raft .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Several runners compete in a road race.'\n",
    "s2 = 'the dog ran quickly to the beach.'\n",
    "\n",
    "def sub_predict(encoder, decoder, s1, s2):\n",
    "    \n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('')    \n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "    \n",
    "# s1 = 'Several runners compete in a road race.'\n",
    "# s2 = 'The people are outside.'\n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'Several runners compete in a road race.'\n",
    "# s2 = 'Some people run in a race.'\n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'Several runners compete in a road race.'\n",
    "# s2 = 'Some runner walks.'\n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "\n",
    "# s1 = 'The runners compete outside in a race.'\n",
    "# s2 = 'The runners move quickly.'\n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'The runners are outside.'\n",
    "# s2 = 'The runners do not walking.'\n",
    "\n",
    "# sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "\n",
    "s1 = 'Some kids are wrestling on an inflatable raft.'\n",
    "s2 = 'the boy is on the beach.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'the kids are outside.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'Some kids wrestle outside in the sun.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'The kids are with an inflatable raft.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'young kids wrestle with each other.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'old children play all over the water.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'the kids wrestle with an fierce determination.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several kids are all on a raft.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'They raft on three kids.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'a rafts used in the match.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s2 = 'the kids are in the water.'\n",
    "sub_predict(encoder, decoder, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Two people pose for the camera.\n",
      "Predicted Entailment:  two people pose for the camera .\n",
      "\n",
      "Sentence:  One person poses for the camera.\n",
      "Predicted Entailment:  one person poses for a camera .\n",
      "\n",
      "Sentence:  A man poses for the camera.\n",
      "Predicted Entailment:  one man poses for the camera .\n",
      "\n",
      "Sentence:  A man is posing for the camera.\n",
      "Predicted Entailment:  a man posing for the camera .\n",
      "\n",
      "Sentence:  A man is posing on the grass.\n",
      "Predicted Entailment:  a man is on the grass .\n",
      "\n",
      "Sentence:  A man is sleeping on the grass.\n",
      "Predicted Entailment:  a man is is down on grass .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Two people pose for the camera.'\n",
    "s2 = 'Two people pose for a picture.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'One person poses for the camera.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'A man poses for the camera.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'A man is posing for the camera.'\n",
    "s2 = 'A man lays for the camera.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "\n",
    "s1 = 'A man is posing on the grass.'\n",
    "s2 = 'A man lays for the camera.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "\n",
    "s1 = 'A man is sleeping on the grass.'\n",
    "s2 = 'The man is laying down to sleep.'\n",
    "sub_predict(encoder, decoder, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some children are playing jump rope.\n",
      "Children are jumping rope.\n",
      "\n",
      "A large golden dog sniffing the butt of a white dog\n",
      "Two animals getting to know each other.\n",
      "\n",
      "A sumo wrestler with a brown belt is pushing another wrestler in a bout.\n",
      "Two sumo wrestlers compete in a match.\n",
      "\n",
      "Two large dogs greet other while their owners watch.\n",
      "the dogs see each other\n",
      "\n",
      "Woman with green sweater and sunglasses smiling\n",
      "A woman with a green sweater has a happy expression.\n",
      "\n",
      "A woman with dark hair is wearing a green sweater.\n",
      "A woman is there.\n",
      "\n",
      "A smiling lady in a green jacket at a public gathering.\n",
      "A happy woman smiling\n",
      "\n",
      "A woman in a green jacket and black sunglasses outside in a crowd.\n",
      "A woman is outside.\n",
      "\n",
      "A climber is making his way up a snowy mountainside.\n",
      "A climber is ascending\n",
      "\n",
      "a lone person jumping through the air from one snowy mountain to another.\n",
      "A person jumps in the air.\n",
      "\n",
      "A man doing tricks in the snow.\n",
      "The man is outside.\n",
      "\n",
      "Two Asian people sit at a blue table in a food court.\n",
      "Two people are seated together.\n",
      "\n",
      "Indian couple holding child near riverbank.\n",
      "A couple is holding a child\n",
      "\n",
      "A bunch of people playing soccer.\n",
      "a bunch of people are playing soccer\n",
      "\n",
      "Two little kids showing their American pride in their star spangled wagon.\n",
      "Two kids are with a wagon.\n",
      "\n",
      "Girl is blowing to a butterfly.\n",
      "The girl blows a butterfly.\n",
      "\n",
      "A small girl stands among many large watermelons.\n",
      "There is a girl standing\n",
      "\n",
      "A child stoops to pick up a watermelon from a large pile of them.\n",
      "A person is near a watermelon.\n",
      "\n",
      "A little girl picking up a watermelon from a pile.\n",
      "A girl is picking an item up.\n",
      "\n",
      "a young girl in a flowery dress surrounded by watermelons\n",
      "There is a lot of fruit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in train_data[200:220]:\n",
    "    print(x.sentence1)\n",
    "    print(x.sentence2)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The little boy is jumping into a puddle on the street.\n",
      "Predicted Entailment:  the boy is in his wet puddle\n",
      "\n",
      "Sentence:  Young players engage in the sport of Water polo while others watch.\n",
      "Predicted Entailment:  the players watch in a other water\n",
      "\n",
      "Sentence:  Some kids are wrestling on an inflatable raft.\n",
      "Predicted Entailment:  some kids are are\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'The little boy is jumping into a puddle on the street.'\n",
    "s2 = 'A boy plays with my favorite puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'An animal is jumping to catch an object.'\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'Young players engage in the sport of Water polo while others watch.'\n",
    "s2 = 'A man jumps in the big puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'Some kids are wrestling on an inflatable raft.'\n",
    "s2 = 'The bed is dirty'\n",
    "s3 = 'The kids are wrestling'\n",
    "sub_predict(encoder, decoder, s1, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a det man some\n",
      "man nsubj stares kids\n",
      "stares ROOT stares are\n",
      "at prep stares on\n",
      "some det puddle a\n",
      "puddle pobj at raft\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    print(item.lower_, item.dep_, item.head, item.pword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some [('a', array([ 0.02479785])), ('the', array([ 0.35729147])), ('some', array([ 0.61051977]))]\n",
      "kids [('people', array([ 0.02372272])), ('kids', array([ 0.68255007])), ('children', array([ 0.26362851]))]\n",
      "are [('is', array([ 0.00296623])), ('were', array([ 0.00402924])), ('are', array([ 0.99073111]))]\n",
      "are [('playing', array([ 0.0363415])), ('kids', array([ 0.03651994])), ('are', array([ 0.49121337]))]\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    probs = np.copy(item.probs)\n",
    "    idx = np.argmax(probs)\n",
    "    indices =  np.argpartition(probs.flatten(), -3)[-3:]\n",
    "    print(decoder.idx_to_wrd[item.dep_][idx], [(decoder.idx_to_wrd[item.dep_][x], probs[x]) for x in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wearing', 'ware', 'does', 'park', 'jump', 'considers', 'snow', 'Player', 'calmly', 'feels', 'Is', 'saliva', 'turned', 'Will', 'bungee', 'outdoors', 'match', 'looks', 'enjoy', 'be', 'swimming', 'outside', 'seafarer', 'crew', 'hate', 'balancing', 'laying', 'wanna', 'been', 'pep', 'TO', 'help', 'will', 'ins', 'to', 'birds', 'band', 'might', 'Can', 'goes', 'adult', 'prepares', 'likes', 'do', 'work', 'would', 'Men', 'should', 'id', 'pretend', 'microwave', 'unknowing', 'rock', 'like', 'doing', 'am', 'sits', 'is', 'busy', 's', 'sunshine', 'willing', 'walks', 'skateboarded', 'para', 'sleeping', 'sitting', 'building', 'competing', 'being', 'woman', 'ARE', 'Waves', 'avoiding', 'tries', 'ski', 'dressed', 'goers', 'leans', 'orange', 'jeep', 'came', 'must', 'have', 'enjoys', 'ride', 'walk', 'were', 'runs', 'n', 'was', 'WERE', 'did', 'stare', 'getting', 'can', 'both', 'inhaling', 'handicapped', 're', 'are', 'IS', 'may', 'shall', 'has', 'having', 'square', 'climbs', 'hang', 'outdoor', 'helping', 'walking', 'tie', 'sled', 'could', 'love', 'gets', 'let', 'concrete', 'lap', 'mask', 'floats', 'hawk', 'give', 'had', 'practices', 'To', 'stands', 'd', 'hugging'}\n"
     ]
    }
   ],
   "source": [
    "print(subvocabs['aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062324425311581\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "correct = 0\n",
    "\n",
    "for item in train_data:\n",
    "    encoder.forward_pass(item.sentence1)\n",
    "    decoder.forward_pass(item.sentence2, encoder.get_root_embedding())\n",
    "    \n",
    "    for node in decoder.tree:\n",
    "        total += 1\n",
    "        if node.pword.lower() == node.lower_:\n",
    "            correct += 1\n",
    "            \n",
    "accuracy = float(correct / total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6167829757904713\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "correct = 0\n",
    "\n",
    "for item in test_data:\n",
    "    encoder.forward_pass(item.sentence1)\n",
    "    decoder.forward_pass(item.sentence2, encoder.get_root_embedding())\n",
    "    \n",
    "    for node in decoder.tree:\n",
    "        total += 1\n",
    "        if node.pword.lower() == node.lower_:\n",
    "            correct += 1\n",
    "            \n",
    "accuracy = float(correct / total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
