{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Sentences with TreeRNNs\n",
    "\n",
    "This notebook goes through a minimal example of encoding one sentence into a distributed representation using a TreeRNN, and the using this distributed representation to generate another sentence using a different TreeRNN in reverse. To start, we'll do some data cleaning to make sure we have a good set of sentence pairs to train on. The main goal here is to remove sentences with mispelled words and oddities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant \n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from pysem.corpora import SNLI\n",
    "from pysem.networks import DependencyNetwork\n",
    "from pysem.generatives import EmbeddingGenerator\n",
    "\n",
    "checker = enchant.Dict('en_US')\n",
    "TrainingPair = namedtuple('TrainingPair', ['sentence1', 'sentence2', 'label'])\n",
    "\n",
    "snli = SNLI('/home/pblouw/snli_1.0/')\n",
    "snli.load_xy_pairs()\n",
    "\n",
    "def repair(sen):\n",
    "    tokens = DependencyNetwork.parser(sen)\n",
    "    if len(tokens) > 15:\n",
    "        return None\n",
    "    for token in tokens:\n",
    "        if not checker.check(token.text):\n",
    "            return None\n",
    "    return sen\n",
    "\n",
    "def clean_data(data):\n",
    "    clean = []\n",
    "    for item in data:\n",
    "        \n",
    "        s1 = repair(item.sentence1)\n",
    "        s2 = repair(item.sentence2)\n",
    "        if s1 == None or s2 == None:\n",
    "            continue\n",
    "        else:\n",
    "            clean.append(TrainingPair(s1, s2, item.label))\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_dev = clean_data(snli.dev_data)\n",
    "clean_train = clean_data(snli.train_data)\n",
    "clean_test = clean_data(snli.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955\n",
      "4839\n",
      "306651\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_dev))\n",
    "print(len(clean_test))\n",
    "print(len(clean_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build a vocab from the set of cleaned sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    vocab = set()\n",
    "    for item in data:\n",
    "        s1 = item.sentence1\n",
    "        s2 = item.sentence2\n",
    "        \n",
    "        t1 = DependencyNetwork.parser(s1)\n",
    "        t2 = DependencyNetwork.parser(s2)\n",
    "        \n",
    "        for t in t1:\n",
    "            if t.text not in vocab:\n",
    "                vocab.add(t.text)\n",
    "        for t in t2:\n",
    "            if t.text not in vocab:\n",
    "                vocab.add(t.text)\n",
    "\n",
    "    return sorted(list(vocab))\n",
    "\n",
    "data = clean_dev + clean_test + clean_train\n",
    "vocab = build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22555\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can collect all of the sentence pairs standing in entailment relations to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106288\n",
      "1666\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "train_data = [d for d in clean_train if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "test_data = [d for d in clean_test if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "dev_data = [d for d in clean_dev if d.label == 'entailment'] # or d.label == 'neutral']\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration  0\n",
      "On iteration  1\n",
      "On iteration  2\n",
      "On iteration  3\n",
      "On iteration  4\n",
      "On iteration  5\n",
      "On iteration  6\n",
      "On iteration  7\n",
      "On iteration  8\n",
      "On iteration  9\n",
      "On iteration  10\n",
      "On iteration  11\n",
      "On iteration  12\n",
      "On iteration  13\n",
      "On iteration  14\n",
      "On iteration  15\n",
      "On iteration  16\n",
      "On iteration  17\n",
      "On iteration  18\n",
      "On iteration  19\n",
      "On iteration  20\n",
      "On iteration  21\n",
      "On iteration  22\n",
      "On iteration  23\n",
      "On iteration  24\n",
      "On iteration  25\n",
      "On iteration  26\n",
      "On iteration  27\n",
      "On iteration  28\n",
      "On iteration  29\n",
      "On iteration  30\n",
      "On iteration  31\n",
      "On iteration  32\n",
      "On iteration  33\n",
      "On iteration  34\n",
      "On iteration  35\n",
      "On iteration  36\n",
      "On iteration  37\n",
      "On iteration  38\n",
      "On iteration  39\n",
      "On iteration  40\n",
      "On iteration  41\n",
      "On iteration  42\n",
      "On iteration  43\n",
      "On iteration  44\n",
      "On iteration  45\n",
      "On iteration  46\n",
      "On iteration  47\n",
      "On iteration  48\n",
      "On iteration  49\n",
      "On iteration  50\n",
      "On iteration  51\n",
      "On iteration  52\n",
      "On iteration  53\n",
      "On iteration  54\n",
      "On iteration  55\n",
      "On iteration  56\n",
      "On iteration  57\n",
      "On iteration  58\n",
      "On iteration  59\n",
      "On iteration  60\n",
      "On iteration  61\n",
      "On iteration  62\n",
      "On iteration  63\n",
      "On iteration  64\n",
      "On iteration  65\n",
      "On iteration  66\n",
      "On iteration  67\n",
      "On iteration  68\n",
      "On iteration  69\n",
      "On iteration  70\n",
      "On iteration  71\n",
      "On iteration  72\n",
      "On iteration  73\n",
      "On iteration  74\n",
      "On iteration  75\n",
      "On iteration  76\n",
      "On iteration  77\n",
      "On iteration  78\n",
      "On iteration  79\n",
      "On iteration  80\n",
      "On iteration  81\n",
      "On iteration  82\n",
      "On iteration  83\n",
      "On iteration  84\n",
      "On iteration  85\n",
      "On iteration  86\n",
      "On iteration  87\n",
      "On iteration  88\n",
      "On iteration  89\n",
      "On iteration  90\n",
      "On iteration  91\n",
      "On iteration  92\n",
      "On iteration  93\n",
      "On iteration  94\n",
      "On iteration  95\n",
      "On iteration  96\n",
      "On iteration  97\n",
      "On iteration  98\n",
      "On iteration  99\n"
     ]
    }
   ],
   "source": [
    "dim = 300\n",
    "iters = 100\n",
    "rate = 0.0006\n",
    "batchsize = 10000\n",
    "\n",
    "vectors = 'w2v_embeddings.pickle'\n",
    "\n",
    "with open('w2v_dep_vocabs.pickle', 'rb') as pfile:\n",
    "    subvocabs = pickle.load(pfile)\n",
    "\n",
    "encoder = DependencyNetwork(dim=dim, vocab=vocab, pretrained=vectors)\n",
    "decoder = EmbeddingGenerator(dim=dim, subvocabs=subvocabs, vectors=vectors)\n",
    "\n",
    "for _ in range(iters):\n",
    "    print('On iteration ', _)\n",
    "    if _ == 60:\n",
    "        rate = rate / 2.0\n",
    "    if _ == 75:\n",
    "        rate = rate / 2.0\n",
    "    if _ == 90:\n",
    "        rate = rate / 2.0\n",
    "    \n",
    "    batch = random.sample(train_data, batchsize)\n",
    "    for sample in batch:\n",
    "        s1 = sample.sentence1\n",
    "        s2 = sample.sentence2\n",
    "\n",
    "        encoder.forward_pass(s1)        \n",
    "        decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "        decoder.backward_pass(rate=rate)\n",
    "        encoder.backward_pass(decoder.pass_grad, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Entailment Generation Examples\n",
    "\n",
    "This small amount of data probably isn't enough to generalize outside of the training set, so we'll first check how well the learned decoder is able to generate the entailments it has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Two young boys running down an upper level breezeway.\n",
      "Predicted Entailment:  the boys are running\n",
      "Actual Entailment:  some boys are running\n",
      "\n",
      "Sentence:  Three people with their back turned are standing inside a building.\n",
      "Predicted Entailment:  three people are their building inside a building\n",
      "Actual Entailment:  three people turn their backs inside the building\n",
      "\n",
      "Sentence:  Young children playing in a pile of toilet paper.\n",
      "Predicted Entailment:  children are playing together .\n",
      "Actual Entailment:  kids are playing together .\n",
      "\n",
      "Sentence:  A man climbing a cliff.\n",
      "Predicted Entailment:  a man is climbing up a cliff .\n",
      "Actual Entailment:  a man is climbing up a cliff .\n",
      "\n",
      "Sentence:  A white dog holds a stick while swimming.\n",
      "Predicted Entailment:  a white dog is swimming .\n",
      "Actual Entailment:  the white dog is swimming .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_trees = [d for d in dev_data if 5 < len(d.sentence2.split()) < 10]\n",
    "batch = random.sample(train_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate entailments using randomly chosen trees for the decoding network structure. This doesn't work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The greyhounds are running quickly in this race.\n",
      "Predicted Entailment:  the greyhounds are running fast in the race .\n",
      "Actual Entailment:  the dogs are running quickly in this race .\n",
      "Random Tree Entailment:  the greyhounds are running a race .\n",
      "\n",
      "Sentence:  Four black teenagers are playing basketball inside a gymnasium while another one watches.\n",
      "Predicted Entailment:  four are playing in a gym .\n",
      "Actual Entailment:  four teenagers playing inside a gym .\n",
      "Random Tree Entailment:  some people are inside a gym .\n",
      "\n",
      "Sentence:  Dog herding cows\n",
      "Predicted Entailment:  dog herding near a livestock .\n",
      "Actual Entailment:  animals are near each other .\n",
      "Random Tree Entailment:  a dog herding near a livestock .\n",
      "\n",
      "Sentence:  A dog runs along the shore of a pond with two elegant geese swimming.\n",
      "Predicted Entailment:  a dog is at the water of the water outside .\n",
      "Actual Entailment:  a dog runs along the edge of a pond outdoors .\n",
      "Random Tree Entailment:  a dog is at the water .\n",
      "\n",
      "Sentence:  A man running a marathon talks to his friend.\n",
      "Predicted Entailment:  there running a people running .\n",
      "Actual Entailment:  there is a man running .\n",
      "Random Tree Entailment:  a man running marathon conversation to to a friend .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = random.sample(dev_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    \n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "\n",
    "    decoder.forward_pass(randsen.sentence2, encoder.get_root_embedding())\n",
    "    alternate = [node.pword for node in decoder.tree]\n",
    "    print('Random Tree Entailment: ', ' '.join(alternate))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Entailment Chains (i.e. Inferential Roles)\n",
    "\n",
    "We can also generate entailment chains by re-encoding a generated sentence, and then generating new sentence from the subsequent encoding. This is kind of neat because it allows us to distill what the model has learned in a network of inferential relationships between sentences. Philosophers sometimes argue that the meaning of sentences is determined by it's role or location in such a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A man curls up in a blanket on the street.\n",
      "Predicted Entailment:  a man is on the blanket .\n",
      "Next Prediction:  a man is outside .\n",
      "\n",
      "Sentence:  A group of Asian men pose around a large table after enjoying a meal together.\n",
      "Predicted Entailment:  a men eating at a table\n",
      "Next Prediction:  the men eating a food .\n",
      "\n",
      "Sentence:  Two police officers are sitting on motorcycles in the road.\n",
      "Predicted Entailment:  two officers are on their road .\n",
      "Next Prediction:  the officers are same outdoors .\n",
      "\n",
      "Sentence:  Five people are playing in a gymnasium.\n",
      "Predicted Entailment:  the people are are together .\n",
      "Next Prediction:  the people are together .\n",
      "\n",
      "Sentence:  A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.\n",
      "Predicted Entailment:  a woman is makeup .\n",
      "Next Prediction:  a female woman makeup new makeup .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'A man curls up in a blanket on the street.'\n",
    "s2 = 'A dog chases in a field.'\n",
    "s3 = 'A frog is cold.'\n",
    "\n",
    "def predict(encoder, decoder, s1, s2, s3):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "\n",
    "    encoder.forward_pass(' '.join(predicted))\n",
    "    decoder.forward_pass(s3, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Next Prediction: ', ' '.join(predicted))\n",
    "    print('')\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "    \n",
    "s1 = 'A group of Asian men pose around a large table after enjoying a meal together.'\n",
    "s2 = 'Some people pose for a picture'\n",
    "s3 = 'The group takes a picture.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Two police officers are sitting on motorcycles in the road.'\n",
    "s2 = 'Two policemen sit on their bikes.'\n",
    "s3 = 'The men have big guns.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Five people are playing in a gymnasium.'\n",
    "s2 = 'Some people are competing indoors.'\n",
    "s3 = 'Some people are inside.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.'\n",
    "s2 = 'The woman applies eyeliner.'\n",
    "s3 = 'The red woman applies green eyeliner.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.\n",
      "Conditioning Context:  A person in a hooded shirt is photographing a woman.\n",
      "Predicted Entailment:  a human is performing makeup\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  fishing\n",
      "Predicted Entailment:  a shirtless man fishing in the blue water .\n",
      "\n",
      "Sentence:  Seven women stand and sit around a waters edge and one of them women sitting in the middle with her bare feet in the water drinks from a water bottle.\n",
      "Conditioning Context:  What is in the water bottle?\n",
      "Predicted Entailment:  a female person sitting in the bottle .\n"
     ]
    }
   ],
   "source": [
    "def condition(encoder, decoder, s1, s2, cond):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding() + cond)\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    \n",
    "s1 = 'A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.'\n",
    "s2 = 'a blond woman applying eyeliner'\n",
    "cond_sen = 'A person in a hooded shirt is photographing a woman.'\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)   \n",
    "\n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'fishing'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "s1 = 'Seven women stand and sit around a waters edge and one of them women sitting in the middle with her bare feet in the water drinks from a water bottle.'\n",
    "s2 = 'a big man is on a boat.'\n",
    "cond_sen = 'What is in the water bottle?'\n",
    "\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "condition(encoder, decoder, s1, s2, cond)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Substitional Analysis\n",
    "\n",
    "Finally, it is also possible to examine the effect a given word or phrase has on entailment generation via substitutions. Essentially, this involves looking at the difference made to the most likely entailment when a given word or phrase in the input sentence is replaced with another word or phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Several runners compete in a road race.\n",
      "Predicted Entailment:  the runners are outside in a race .\n",
      "\n",
      "Sentence:  Many runners compete in a road race.\n",
      "Predicted Entailment:  the runners are outside in a race .\n",
      "\n",
      "Sentence:  Several runners compete in a talent show.\n",
      "Predicted Entailment:  the people compete together in a show .\n",
      "\n",
      "Sentence:  Several performers compete in a talent show.\n",
      "Predicted Entailment:  the performers compete together in a show .\n",
      "\n",
      "Sentence:  Several performers perform in a music show.\n",
      "Predicted Entailment:  the performers performing together in a show .\n",
      "\n",
      "Sentence:  Several swimmers compete in a fast race.\n",
      "Predicted Entailment:  the swimmers are fast in a race .\n",
      "\n",
      "Sentence:  The swimmers compete in a road race.\n",
      "Predicted Entailment:  the people are in the race .\n",
      "\n",
      "Sentence:  The swimmers compete in a swim race.\n",
      "Predicted Entailment:  the swim swimmers are in a race .\n",
      "\n",
      "Sentence:  Several runners paint paintings.\n",
      "Predicted Entailment:  the several people paint in the painting .\n",
      "\n",
      "Sentence:  The swimmers race before eating.\n",
      "Predicted Entailment:  the large people are at the race .\n",
      "\n",
      "Sentence:  One very slow cyclist is in the indoor arena.\n",
      "Predicted Entailment:  the indoor athlete is in a event .\n",
      "\n",
      "Sentence:  a little boy is in the water.\n",
      "Predicted Entailment:  a little boy is in the water .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Several runners compete in a road race.'\n",
    "s2 = 'the dog ran quickly to the beach.'\n",
    "\n",
    "def sub_predict(encoder, decoder, s1, s2):\n",
    "    \n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('')    \n",
    "\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "    \n",
    "s1 = 'Many runners compete in a road race.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several runners compete in a talent show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several performers compete in a talent show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several performers perform in a music show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several swimmers compete in a fast race.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers compete in a road race.'\n",
    "s2 = 'the boy is on the beach.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers compete in a swim race.'\n",
    "s2 = 'a big man sits near that beach.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several runners paint paintings.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers race before eating.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'One very slow cyclist is in the indoor arena.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'a little boy is in the water.'\n",
    "sub_predict(encoder, decoder, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Young blond woman putting her foot into a water fountain\n",
      "A person is dipping her foot into water.\n",
      "\n",
      "A young woman tries to stick her foot in a fountain.\n",
      "A woman is near a fountain.\n",
      "\n",
      "A young woman tries to stick her foot in a fountain.\n",
      "The woman has one foot in the air.\n",
      "\n",
      "Woman balancing on edge of fountain while sticking her toe in the water.\n",
      "A woman stand on a fountain and dips her toes in.\n",
      "\n",
      "A couple strolls arm and arm and hand in hand down a city sidewalk.\n",
      "The couple is outdoors.\n",
      "\n",
      "A man stare at a passing couple while walking down the block.\n",
      "A man stares at a passing couple.\n",
      "\n",
      "Two men in wheelchairs are reaching in the air for a basketball.\n",
      "Two people in wheelchairs are reaching in the air for a basketball.\n",
      "\n",
      "Three dogs in different shades of brown and white biting and licking each other.\n",
      "there are three dogs\n",
      "\n",
      "Three small puppies bite and play together in the grass.\n",
      "Three puppies are playing outside.\n",
      "\n",
      "Two dogs biting another dog in a field.\n",
      "dogs attacking another dog\n",
      "\n",
      "Tourists waiting at a train stop.\n",
      "A group of tourist waiting for a train at a train station.\n",
      "\n",
      "A woman with a black jacket walks past an outdoor movie poster.\n",
      "A woman walking outside.\n",
      "\n",
      "Indian lady and a guy in a blue suit dancing in the sunlight.\n",
      "Two people dancing outdoors.\n",
      "\n",
      "Two older men are talking.\n",
      "Two people are having a conversation.\n",
      "\n",
      "A mountain biker jumping a slope outdoors in a forest area.\n",
      "A biker is doing jumps by trees.\n",
      "\n",
      "A mountain biker jumping a slope outdoors in a forest area.\n",
      "The biker is jumping into a hole.\n",
      "\n",
      "A mountain biker jumping a slope outdoors in a forest area.\n",
      "A person rides a bike outdoors.\n",
      "\n",
      "A mountain biker jumping a slope outdoors in a forest area.\n",
      "They are avoiding trees.\n",
      "\n",
      "Two men are standing outside and snow is on the ground.\n",
      "People are near snow.\n",
      "\n",
      "Two older men in coats are standing outside.\n",
      "They are outside wearing coats.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in train_data[70:90]:\n",
    "    print(x.sentence1)\n",
    "    print(x.sentence2)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The little boy is jumping into a puddle on the street.\n",
      "Predicted Entailment:  the boy is in his wet puddle\n",
      "\n",
      "Sentence:  Young players engage in the sport of Water polo while others watch.\n",
      "Predicted Entailment:  some players watch in an other polo\n",
      "\n",
      "Sentence:  A woman dancing by two men above the ceiling.\n",
      "Predicted Entailment:  the woman dancing near the men\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'The little boy is jumping into a puddle on the street.'\n",
    "s2 = 'A boy plays with my favorite puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'An animal is jumping to catch an object.'\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'Young players engage in the sport of Water polo while others watch.'\n",
    "s2 = 'A man jumps in the big puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'A woman dancing by two men above the ceiling.'\n",
    "s2 = 'The bed is dirty'\n",
    "s3 = 'A man stares at some puddle'\n",
    "sub_predict(encoder, decoder, s1, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a det man the\n",
      "man nsubj stares woman\n",
      "stares ROOT stares dancing\n",
      "at prep stares near\n",
      "some det puddle the\n",
      "puddle pobj at men\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    print(item.lower_, item.dep_, item.head, item.pword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the [('some', array([ 0.01932157])), ('a', array([ 0.43674835])), ('the', array([ 0.54203248]))]\n",
      "woman [('people', array([ 0.06433475])), ('women', array([ 0.2472285])), ('woman', array([ 0.5238112]))]\n",
      "dancing [('are', array([ 0.05906747])), ('is', array([ 0.10831368])), ('dancing', array([ 0.14677156]))]\n",
      "near [('by', array([ 0.13327161])), ('in', array([ 0.14761176])), ('near', array([ 0.16761699]))]\n",
      "the [('some', array([ 0.01390214])), ('a', array([ 0.045567])), ('the', array([ 0.9380372]))]\n",
      "men [('girls', array([ 0.05206402])), ('women', array([ 0.12743021])), ('men', array([ 0.59933989]))]\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    probs = np.copy(item.probs)\n",
    "    idx = np.argmax(probs)\n",
    "    indices =  np.argpartition(probs.flatten(), -3)[-3:]\n",
    "    print(decoder.idx_to_wrd[item.dep_][idx], [(decoder.idx_to_wrd[item.dep_][x], probs[x]) for x in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stands', 'WERE', 'was', 'inhaling', 'walks', 'mask', 'am', 'hawk', 'square', 'has', 'outdoors', 're', 'give', 'love', 'would', 'jeep', 'being', 's', 'outdoor', 'unknowing', 'orange', 'practices', 'laying', 'goers', 'having', 'match', 'will', 'turned', 'ride', 'seafarer', 'ware', 'doing', 'goes', 'Men', 'Waves', 'getting', 'looks', 'outside', 'microwave', 'feels', 'stare', 'swimming', 'enjoys', 'both', 'ski', 'hugging', 'Player', 'have', 'handicapped', 'may', 'were', 'sits', 'prepares', 'sunshine', 'dressed', 'bungee', 'concrete', 'help', 'ARE', 'avoiding', 'crew', 'sitting', 'wearing', 'considers', 'band', 'birds', 'be', 'jump', 'been', 'd', 'sleeping', 'busy', 'pretend', 'id', 'shall', 'park', 'tries', 'gets', 'to', 'rock', 'willing', 'n', 'is', 'snow', 'tie', 'can', 'did', 'calmly', 'leans', 'hate', 'floats', 'enjoy', 'walk', 'building', 'had', 'sled', 'Is', 'lap', 'para', 'Will', 'must', 'should', 'are', 'could', 'runs', 'likes', 'TO', 'balancing', 'does', 'pep', 'To', 'walking', 'wanna', 'IS', 'might', 'woman', 'came', 'work', 'like', 'climbs', 'adult', 'ins', 'do', 'skateboarded', 'helping', 'let', 'Can', 'hang', 'competing', 'saliva'}\n"
     ]
    }
   ],
   "source": [
    "print(subvocabs['aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705805488400173\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "correct = 0\n",
    "\n",
    "for item in train_data:\n",
    "    encoder.forward_pass(item.sentence1)\n",
    "    decoder.forward_pass(item.sentence2, encoder.get_root_embedding())\n",
    "    \n",
    "    for node in decoder.tree:\n",
    "        total += 1\n",
    "        if node.pword.lower() == node.lower_:\n",
    "            correct += 1\n",
    "            \n",
    "accuracy = float(correct / total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6186783837339537\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "correct = 0\n",
    "\n",
    "for item in test_data:\n",
    "    encoder.forward_pass(item.sentence1)\n",
    "    decoder.forward_pass(item.sentence2, encoder.get_root_embedding())\n",
    "    \n",
    "    for node in decoder.tree:\n",
    "        total += 1\n",
    "        if node.pword.lower() == node.lower_:\n",
    "            correct += 1\n",
    "            \n",
    "accuracy = float(correct / total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
