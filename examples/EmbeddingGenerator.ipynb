{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Sentences with TreeRNNs\n",
    "\n",
    "This notebook goes through a minimal example of encoding one sentence into a distributed representation using a TreeRNN, and the using this distributed representation to generate another sentence using a different TreeRNN in reverse. To start, we'll do some data cleaning to make sure we have a good set of sentence pairs to train on. The main goal here is to remove sentences with mispelled words and oddities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant \n",
    "import random\n",
    "import pickle\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim \n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from pysem.corpora import SNLI\n",
    "from pysem.networks import DependencyNetwork\n",
    "from pysem.generatives import EmbeddingGenerator\n",
    "\n",
    "checker = enchant.Dict('en_US')\n",
    "TrainingPair = namedtuple('TrainingPair', ['sentence1', 'sentence2', 'label'])\n",
    "\n",
    "snli = SNLI('/Users/peterblouw/corpora/snli_1.0/')\n",
    "snli.load_xy_pairs()\n",
    "\n",
    "def repair(sen):\n",
    "    words = nltk.word_tokenize(sen)\n",
    "    for word in words:\n",
    "        if not checker.check(word):\n",
    "            return None\n",
    "    return sen\n",
    "\n",
    "def clean_data(data):\n",
    "    clean = []\n",
    "    for item in data:\n",
    "        \n",
    "        s1 = repair(item.sentence1)\n",
    "        s2 = repair(item.sentence2)\n",
    "        if s1 == None or s2 == None:\n",
    "            continue\n",
    "        else:\n",
    "            clean.append(TrainingPair(s1, s2, item.label))\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_dev = clean_data(snli.dev_data)\n",
    "clean_train = clean_data(snli.train_data)\n",
    "clean_test = clean_data(snli.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to see whether any words in our cleaned data are missing from our model of Word2Vec embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2013', '50', '916', '2012', 'of', '10', 'a', '15', 'to', '40', 'and', '.', '52'}\n",
      "24910\n"
     ]
    }
   ],
   "source": [
    "with open('w2v_embeddings.pickle', 'rb') as pfile:\n",
    "    model = pickle.load(pfile)\n",
    "\n",
    "acc = []\n",
    "def w2v_check(sen):\n",
    "    words = nltk.word_tokenize(sen)\n",
    "    for word in words:\n",
    "        if word not in model:\n",
    "            acc.append(word)\n",
    "            return None\n",
    "\n",
    "for item in clean_dev:\n",
    "    s1 = item.sentence1\n",
    "    s2 = item.sentence2\n",
    "    \n",
    "    w2v_check(s1)\n",
    "    w2v_check(s2)\n",
    "\n",
    "print(set(acc))\n",
    "print(len(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build a vocab from the set of cleaned sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    vocab = set()\n",
    "    for item in data:\n",
    "        s1 = item.sentence1\n",
    "        s2 = item.sentence2\n",
    "        \n",
    "        t1 = nltk.word_tokenize(s1)\n",
    "        t2 = nltk.word_tokenize(s2)\n",
    "        \n",
    "        for t in t1:\n",
    "            if t not in vocab:\n",
    "                vocab.add(t)\n",
    "        for t in t2:\n",
    "            if t not in vocab:\n",
    "                vocab.add(t)\n",
    "\n",
    "    return sorted(list(vocab))\n",
    "\n",
    "data = clean_dev + clean_test + clean_train\n",
    "vocab = build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25280\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depsets = {dep: set() for dep in DependencyNetwork.deps}\n",
    "depsets[''] = set()\n",
    "\n",
    "parser = spacy.load('en')\n",
    "data = clean_dev + clean_test + clean_train\n",
    "\n",
    "for item in data:\n",
    "    s1 = item.sentence1\n",
    "    s2 = item.sentence2\n",
    "\n",
    "    s1_parse = parser(s1)\n",
    "    s2_parse = parser(s2)\n",
    "\n",
    "    for token in s1_parse:\n",
    "        if token.text not in depsets[token.dep_]:\n",
    "            depsets[token.dep_].add(token.text)\n",
    "    for token in s2_parse:\n",
    "        if token.text not in depsets[token.dep_]:\n",
    "            depsets[token.dep_].add(token.text)\n",
    "            \n",
    "with open('w2v_dep_vocabs.pickle', 'wb') as pfile:\n",
    "    pickle.dump(depsets, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25283\n",
      "25280\n"
     ]
    }
   ],
   "source": [
    "acc = set()\n",
    "for x in depsets:\n",
    "    for y in depsets[x]:\n",
    "        if y not in acc:\n",
    "            acc.add(y)\n",
    "print(len(acc))\n",
    "print(len(vocab))\n",
    "\n",
    "count = 0\n",
    "for x in vocab:\n",
    "    if x not in model:\n",
    "        count += 1\n",
    "\n",
    "print(len(new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415\n"
     ]
    }
   ],
   "source": [
    "train_data = [d for d in clean_train if d.label == 'entailment']\n",
    "test_data = [d for d in clean_test if d.label == 'entailment']\n",
    "dev_data = [d for d in clean_dev if d.label == 'entailment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration  0\n",
      "On iteration  1\n",
      "On iteration  2\n",
      "On iteration  3\n",
      "On iteration  4\n",
      "On iteration  5\n",
      "On iteration  6\n",
      "On iteration  7\n",
      "On iteration  8\n",
      "On iteration  9\n",
      "On iteration  10\n",
      "On iteration  11\n",
      "On iteration  12\n",
      "On iteration  13\n",
      "On iteration  14\n",
      "On iteration  15\n",
      "On iteration  16\n",
      "On iteration  17\n",
      "On iteration  18\n",
      "On iteration  19\n"
     ]
    }
   ],
   "source": [
    "dim = 300\n",
    "iters = 20\n",
    "rate = 0.0002\n",
    "batchsize = 5000\n",
    "vectors = 'w2v_embeddings.pickle'\n",
    "\n",
    "with open('w2v_dep_vocabs.pickle', 'rb') as pfile:\n",
    "    subvocabs = pickle.load(pfile)\n",
    "\n",
    "encoder = DependencyNetwork(dim=dim, vocab=vocab, pretrained=vectors)\n",
    "decoder = EmbeddingGenerator(dim=dim, subvocabs=subvocabs, vectors=vectors)\n",
    "\n",
    "for _ in range(iters):\n",
    "    print('On iteration ', _)\n",
    "    batch = random.sample(train_data, batchsize)\n",
    "    for sample in batch:\n",
    "        s1 = sample.sentence1\n",
    "        s2 = sample.sentence2\n",
    "\n",
    "        encoder.forward_pass(s1)        \n",
    "        decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "        decoder.backward_pass(rate=rate)\n",
    "        encoder.backward_pass(decoder.pass_grad, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Entailment Generation Examples\n",
    "\n",
    "This small amount of data probably isn't enough to generalize outside of the training set, so we'll first check how well the learned decoder is able to generate the entailments it has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Two dogs biting each other playfully while jumping\n",
      "Predicted Entailment:  two dogs are biting .\n",
      "Actual Entailment:  two dogs are playing .\n",
      "\n",
      "Sentence:  A group of constructions workers lifting a bathtub.\n",
      "Predicted Entailment:  are working\n",
      "Actual Entailment:  humans working\n",
      "\n",
      "Sentence:  A smiling woman is playing the violin in front of a turquoise background.\n",
      "Predicted Entailment:  the woman is playing an instrument .\n",
      "Actual Entailment:  a woman is playing an instrument .\n",
      "\n",
      "Sentence:  Number 916 is hoping that he is going to win the race.\n",
      "Predicted Entailment:  the people is going in a race .\n",
      "Actual Entailment:  a person is competing in a race .\n",
      "\n",
      "Sentence:  A man in glasses and a striped shirt walks down the street with one hand in his pocket.\n",
      "Predicted Entailment:  the man is walks outside\n",
      "Actual Entailment:  a man is walking somewhere\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_trees = [d for d in dev_data if 5 < len(d.sentence2.split()) < 10]\n",
    "batch = random.sample(dev_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate entailments using randomly chosen trees for the decoding network structure. This doesn't work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Two women in bathing suit on large rocks at the ocean.\n",
      "Predicted Entailment:  two women are outside\n",
      "Actual Entailment:  two women are outside\n",
      "Random Tree Entailment:  the women are on the ocean .\n",
      "\n",
      "Sentence:  Hiker in blue shirt and red shorts stands on hill near mountain.\n",
      "Predicted Entailment:  the hiker hiker shirt on .\n",
      "Actual Entailment:  the hiker has shorts on .\n",
      "Random Tree Entailment:  there hiker red hiker on the mountain of mountain .\n",
      "\n",
      "Sentence:  A man in a bar drinks from a pitcher while a man in a green hat looks on and a woman in a black shirt drink from a glass.\n",
      "Predicted Entailment:  a drinking at other bar .\n",
      "Actual Entailment:  a women in black drinks .\n",
      "Random Tree Entailment:  a man is drinking his drink drink .\n",
      "\n",
      "Sentence:  A woman in an orange shirt is enjoying food in a public setting.\n",
      "Predicted Entailment:  a woman in a red shirt is is\n",
      "Actual Entailment:  the lady in the orange shirt is eating\n",
      "Random Tree Entailment:  a is in a food food .\n",
      "\n",
      "Sentence:  A man in a restaurant having lunch.\n",
      "Predicted Entailment:  the man is is .\n",
      "Actual Entailment:  the man is eating .\n",
      "Random Tree Entailment:  a is in restaurant eating outside\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = random.sample(dev_data, 5)\n",
    "\n",
    "for sample in batch:\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "    randsen = random.choice(sample_trees)\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    \n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('Actual Entailment: ', ' '.join(true))\n",
    "\n",
    "    decoder.forward_pass(randsen.sentence2, encoder.get_root_embedding())\n",
    "    alternate = [node.pword for node in decoder.tree]\n",
    "    print('Random Tree Entailment: ', ' '.join(alternate))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Entailment Chains (i.e. Inferential Roles)\n",
    "\n",
    "We can also generate entailment chains by re-encoding a generated sentence, and then generating new sentence from the subsequent encoding. This is kind of neat because it allows us to distill what the model has learned in a network of inferential relationships between sentences. Philosophers sometimes argue that the meaning of sentences is determined by it's role or location in such a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A man curls up in a blanket on the street.\n",
      "Predicted Entailment:  a man is on the street .\n",
      "Next Prediction:  a man is outside .\n",
      "\n",
      "Sentence:  A group of Asian men pose around a large table after enjoying a meal together.\n",
      "Predicted Entailment:  the group are at a table\n",
      "Next Prediction:  the group are a table .\n",
      "\n",
      "Sentence:  Two police officers are sitting on motorcycles in the road.\n",
      "Predicted Entailment:  two officers are on their road .\n",
      "Next Prediction:  the people are other road .\n",
      "\n",
      "Sentence:  Five people are playing in a gymnasium.\n",
      "Predicted Entailment:  the people are are outside .\n",
      "Next Prediction:  the people are outside .\n",
      "\n",
      "Sentence:  A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.\n",
      "Predicted Entailment:  a woman is makeup .\n",
      "Next Prediction:  a female woman makeup black makeup .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'A man curls up in a blanket on the street.'\n",
    "s2 = 'A dog chases in a field.'\n",
    "s3 = 'A frog is cold.'\n",
    "\n",
    "def predict(encoder, decoder, s1, s2, s3):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "\n",
    "    encoder.forward_pass(' '.join(predicted))\n",
    "    decoder.forward_pass(s3, encoder.get_root_embedding())\n",
    "\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Next Prediction: ', ' '.join(predicted))\n",
    "    print('')\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "    \n",
    "s1 = 'A group of Asian men pose around a large table after enjoying a meal together.'\n",
    "s2 = 'Some people pose for a picture'\n",
    "s3 = 'The group takes a picture.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Two police officers are sitting on motorcycles in the road.'\n",
    "s2 = 'Two policemen sit on their bikes.'\n",
    "s3 = 'The men have big guns.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'Five people are playing in a gymnasium.'\n",
    "s2 = 'Some people are competing indoors.'\n",
    "s3 = 'Some people are inside.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)\n",
    "\n",
    "s1 = 'A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.'\n",
    "s2 = 'The woman applies eyeliner.'\n",
    "s3 = 'The red woman applies green eyeliner.'\n",
    "\n",
    "predict(encoder, decoder, s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.\n",
      "Conditioning Context:  A person in a hooded shirt is photographing a woman.\n",
      "Predicted Entailment:  a human is wearing picture\n",
      "\n",
      "Sentence:  A shirtless man sleeps in his blue boat out on the open waters.\n",
      "Conditioning Context:  fishing\n",
      "Predicted Entailment:  a shirtless man fishing on the fishing boat .\n",
      "\n",
      "Sentence:  Seven women stand and sit around a waters edge and one of them women sitting in the middle with her bare feet in the water drinks from a water bottle.\n",
      "Conditioning Context:  What is in the water bottle?\n",
      "Predicted Entailment:  the young people are in the water .\n"
     ]
    }
   ],
   "source": [
    "def condition(encoder, decoder, s1, s2, cond):\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding() + cond)\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    \n",
    "s1 = 'A woman, whose face can only be seen in a mirror, is applying eyeliner in a dimly lit room.'\n",
    "s2 = 'a blond woman applying eyeliner'\n",
    "cond_sen = 'A person in a hooded shirt is photographing a woman.'\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)   \n",
    "\n",
    "s1 = 'A shirtless man sleeps in his blue boat out on the open waters.'\n",
    "s2 = 'The red man is in the big boat.'\n",
    "cond_word = 'fishing'\n",
    "cond = encoder.vectors[cond_word]\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_word)\n",
    "\n",
    "encoder.forward_pass('')\n",
    "condition(encoder, decoder, s1, s2, cond)\n",
    "\n",
    "s1 = 'Seven women stand and sit around a waters edge and one of them women sitting in the middle with her bare feet in the water drinks from a water bottle.'\n",
    "s2 = 'a big man is on a boat.'\n",
    "cond_sen = 'What is in the water bottle?'\n",
    "\n",
    "encoder.forward_pass(cond_sen)\n",
    "cond = encoder.get_root_embedding()\n",
    "\n",
    "print('')\n",
    "print('Sentence: ', s1)\n",
    "print('Conditioning Context: ', cond_sen)\n",
    "\n",
    "condition(encoder, decoder, s1, s2, cond)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Substitional Analysis\n",
    "\n",
    "Finally, it is also possible to examine the effect a given word or phrase has on entailment generation via substitutions. Essentially, this involves looking at the difference made to the most likely entailment when a given word or phrase in the input sentence is replaced with another word or phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Several runners compete in a road race.\n",
      "Predicted Entailment:  the runners runners outside in a race .\n",
      "\n",
      "Sentence:  Many runners compete in a road race.\n",
      "Predicted Entailment:  the runners runners outside in a race .\n",
      "\n",
      "Sentence:  Several runners compete in a talent show.\n",
      "Predicted Entailment:  the people compete outside in a compete .\n",
      "\n",
      "Sentence:  Several performers compete in a talent show.\n",
      "Predicted Entailment:  the performers compete together in a competition .\n",
      "\n",
      "Sentence:  Several performers perform in a music show.\n",
      "Predicted Entailment:  the performers performing together in a stage .\n",
      "\n",
      "Sentence:  Several swimmers compete in a fast race.\n",
      "Predicted Entailment:  the swimmers compete outside in a race .\n",
      "\n",
      "Sentence:  The swimmers compete in a road race.\n",
      "Predicted Entailment:  the people compete in the race .\n",
      "\n",
      "Sentence:  The swimmers compete in a swim race.\n",
      "Predicted Entailment:  the young swimmers swim in the race .\n",
      "\n",
      "Sentence:  Several runners paint paintings.\n",
      "Predicted Entailment:  the several people painting in a paint .\n",
      "\n",
      "Sentence:  The swimmers race before eating.\n",
      "Predicted Entailment:  the several people swimmers in the race .\n",
      "\n",
      "Sentence:  One very slow cyclist is in the indoor arena.\n",
      "Predicted Entailment:  the young cyclist is in the arena .\n",
      "\n",
      "Sentence:  a little boy is in the water.\n",
      "Predicted Entailment:  a little boy is in the water .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Several runners compete in a road race.'\n",
    "s2 = 'the dog ran quickly to the beach.'\n",
    "\n",
    "def sub_predict(encoder, decoder, s1, s2):\n",
    "    \n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(s2, encoder.get_root_embedding())\n",
    "\n",
    "    true = [node.lower_ for node in decoder.tree]\n",
    "    predicted = [node.pword for node in decoder.tree]\n",
    "\n",
    "    print('Sentence: ', s1)\n",
    "    print('Predicted Entailment: ', ' '.join(predicted))\n",
    "    print('')    \n",
    "\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "    \n",
    "s1 = 'Many runners compete in a road race.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several runners compete in a talent show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several performers compete in a talent show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several performers perform in a music show.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several swimmers compete in a fast race.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers compete in a road race.'\n",
    "s2 = 'the boy is on the beach.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers compete in a swim race.'\n",
    "s2 = 'a big man sits near that beach.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'Several runners paint paintings.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'The swimmers race before eating.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'One very slow cyclist is in the indoor arena.'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "s1 = 'a little boy is in the water.'\n",
    "sub_predict(encoder, decoder, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man in a black shirt is smiling at a woman in a black shirt what a tattoo and a eye brow ring.\n",
      "A man is smiling at a woman.\n",
      "\n",
      "A goalie in white runs for an approaching ball while the opponent in red who kicked it waits.\n",
      "A person wearing white is running towards a ball that was kicked from another person.\n",
      "\n",
      "kids drawing something on paper\n",
      "There are kids drawing.\n",
      "\n",
      "A young woman is singing into a microphone.\n",
      "The woman is singing.\n",
      "\n",
      "A diver is swimming with a turtle.\n",
      "A turtle has a diver swimming with it.\n",
      "\n",
      "A man with a beard skateboarding and a boy with a blue and black backpack riding a green bike in the background.\n",
      "There is a man and a boy outside.\n",
      "\n",
      "A young boy reaches for and touches the propeller of a vintage aircraft.\n",
      "A young boy and an airplane.\n",
      "\n",
      "Indian people dressed in magnificent bright colors conduct a ritual.\n",
      "Indian people having a ritual\n",
      "\n",
      "Two little girls ride an inflatable dinghy down a purple water slide.\n",
      "Two girls on a water slide.\n",
      "\n",
      "Young girl with dark hair facing camera and holding a paper bag while wearing an orange shirt and multicolored butterfly wings.\n",
      "A young girl faces the camera.\n",
      "\n",
      "A boy in overalls blows bubbles.\n",
      "A boy is blowing bubbles.\n",
      "\n",
      "Two children playing on the floor with toy trains.\n",
      "The children played on the floor.\n",
      "\n",
      "A white dog is chasing a stuffed animal being pulled on a string.\n",
      "the animal is running\n",
      "\n",
      "Two female workers sit on some steps during work.\n",
      "Two friends sitting on step at their job.\n",
      "\n",
      "Two female workers sit on some steps during work.\n",
      "Two women sitting on steps at their job.\n",
      "\n",
      "Two boys stand in an ocean as the sun sets.\n",
      "Boys are standing\n",
      "\n",
      "Four girls are dancing in matching outfits at a street festival.\n",
      "The four girls are attending the street festival.\n",
      "\n",
      "A child is looking out of a door.\n",
      "There is a door.\n",
      "\n",
      "A boy in a baseball cap jumps over a flight of stairs.\n",
      "A boy jumping through the air.\n",
      "\n",
      "A man is sitting in on the side of the street with brass pots.\n",
      "A man is sitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in dev_data[70:90]:\n",
    "    print(x.sentence1)\n",
    "    print(x.sentence2)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The little boy is jumping into a puddle on the street.\n",
      "Predicted Entailment:  the boy is into his little puddle\n",
      "\n",
      "Sentence:  Young players engage in the sport of Water polo while others watch.\n",
      "Predicted Entailment:  the people playing in the other water\n",
      "\n",
      "Sentence:  A woman dancing by two men above the ceiling.\n",
      "Predicted Entailment:  the women dancing in the men\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'The little boy is jumping into a puddle on the street.'\n",
    "s2 = 'A boy plays with my favorite puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s1 = 'An animal is jumping to catch an object.'\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'Young players engage in the sport of Water polo while others watch.'\n",
    "s2 = 'A man jumps in the big puddle'\n",
    "sub_predict(encoder, decoder, s1, s2)\n",
    "\n",
    "# s2 = 'A white moose walks.'\n",
    "s1 = 'A woman dancing by two men above the ceiling.'\n",
    "s2 = 'The bed is dirty'\n",
    "s3 = 'A man stares at some puddle'\n",
    "sub_predict(encoder, decoder, s1, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the det bed  a\n",
      "bed nsubj is  woman\n",
      "is ROOT is  is\n",
      "dirty acomp is  outside\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    print(item.lower_, item.dep_, item.head, item.pword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [('an', array([ 0.00979189])), ('the', array([ 0.37057355])), ('a', array([ 0.61028682]))]\n",
      "woman [('she', array([ 0.01600048])), ('lady', array([ 0.01862793])), ('woman', array([ 0.90540286]))]\n",
      "is [('jumping', array([ 0.02618057])), ('is', array([ 0.07478745])), ('jumps', array([ 0.03118227]))]\n",
      "outside [('wet', array([ 0.03886075])), ('asleep', array([ 0.05742537])), ('outside', array([ 0.1132588]))]\n"
     ]
    }
   ],
   "source": [
    "for item in decoder.tree:\n",
    "    probs = np.copy(item.probs)\n",
    "    idx = np.argmax(probs)\n",
    "    indices =  np.argpartition(probs.flatten(), -3)[-3:]\n",
    "    print(decoder.idx_to_wrd[item.dep_][idx], [(decoder.idx_to_wrd[item.dep_][x], probs[x]) for x in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(subvocabs['aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
