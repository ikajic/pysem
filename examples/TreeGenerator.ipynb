{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration  0\n",
      "On iteration  1\n",
      "On iteration  2\n",
      "On iteration  3\n",
      "On iteration  4\n",
      "On iteration  5\n",
      "On iteration  6\n",
      "On iteration  7\n",
      "On iteration  8\n",
      "On iteration  9\n",
      "On iteration  10\n",
      "On iteration  11\n",
      "On iteration  12\n",
      "On iteration  13\n",
      "On iteration  14\n",
      "On iteration  15\n",
      "On iteration  16\n",
      "On iteration  17\n",
      "On iteration  18\n",
      "On iteration  19\n",
      "On iteration  20\n",
      "On iteration  21\n",
      "On iteration  22\n",
      "On iteration  23\n",
      "On iteration  24\n",
      "On iteration  25\n",
      "On iteration  26\n",
      "On iteration  27\n",
      "On iteration  28\n",
      "On iteration  29\n",
      "On iteration  30\n",
      "On iteration  31\n",
      "On iteration  32\n",
      "On iteration  33\n",
      "On iteration  34\n",
      "On iteration  35\n",
      "On iteration  36\n",
      "On iteration  37\n",
      "On iteration  38\n",
      "On iteration  39\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from pysem.corpora import SNLI\n",
    "from pysem.networks import DependencyNetwork\n",
    "from pysem.generatives import EmbeddingGenerator, TreeGenerator\n",
    "\n",
    "snli = SNLI('/Users/peterblouw/corpora/snli_1.0/')\n",
    "snli.extractor = snli.get_xy_pairs\n",
    "snli.load_vocab('snli_words.pickle')\n",
    "\n",
    "vectors = 'pretrained_snli_embeddings.pickle'\n",
    "\n",
    "with open('depdict', 'rb') as pfile:\n",
    "    depsets = pickle.load(pfile)\n",
    "\n",
    "dev_data = [d for d in snli.dev_data if d.label == 'entailment']\n",
    "\n",
    "dim = 400\n",
    "iters = 40\n",
    "rate = 0.05\n",
    "batchsize = 10\n",
    "\n",
    "encoder = DependencyNetwork(dim=dim, vocab=snli.vocab)\n",
    "decoder = TreeGenerator(dim=dim, vocab=snli.vocab)\n",
    "\n",
    "for _ in range(iters):\n",
    "    print('On iteration ', _)\n",
    "    for sample in random.sample(dev_data[:15], batchsize):\n",
    "        s1 = sample.sentence1\n",
    "        s2 = sample.sentence2\n",
    "\n",
    "        encoder.forward_pass(s1)\n",
    "        decoder.forward_pass(encoder.get_root_embedding(), s2)\n",
    "        decoder.backward_pass(rate=rate)\n",
    "        encoder.backward_pass(decoder.pass_grad, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source Sentence:  Two women are embracing while holding to go packages.\n",
      "Correct Entailment:  Two woman are holding packages.\n",
      "Predicted Entailment:  two woman are holding packages .\n",
      "\n",
      "Source Sentence:  Two young children in blue jerseys, one with the number 9 and one with the number 2 are standing on wooden steps in a bathroom and washing their hands in a sink.\n",
      "Correct Entailment:  Two kids in numbered jerseys wash their hands.\n",
      "Predicted Entailment:  two kids in numbered jerseys wash their hands .\n"
     ]
    }
   ],
   "source": [
    "for sample in random.sample(dev_data[:10], 2):\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.forward_pass(encoder.get_root_embedding(), s2)\n",
    "    \n",
    "    print('')\n",
    "    print('Source Sentence: ', s1)\n",
    "    print('Correct Entailment: ', s2)\n",
    "    \n",
    "    predicted = []\n",
    "    encoder.forward_pass(s2)\n",
    "    for node in encoder.tree:\n",
    "        for other_node in decoder.sequence:\n",
    "            if other_node.dep_ == node.dep_ and other_node.lower_ == node.lower_ and node.head.lower_ == other_node.head.lower_:\n",
    "                predicted.append(other_node.pw)\n",
    "        \n",
    "    print('Predicted Entailment: ', ' '.join(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two young boys of opposing teams play football, while wearing full protection uniforms and helmets.\n",
      "boys play football\n",
      "play ROOT play\n",
      "boys nsubj play\n",
      "football dobj play\n",
      "\n",
      "Two men on bicycles competing in a race.\n",
      "People are riding bikes.\n",
      "riding ROOT riding\n",
      "people nsubj riding\n",
      "are aux riding\n",
      "bikes dobj riding\n"
     ]
    }
   ],
   "source": [
    "for sample in random.sample(dev_data[:10], 2):\n",
    "    s1 = sample.sentence1\n",
    "    s2 = sample.sentence2\n",
    "\n",
    "    encoder.forward_pass(s1)\n",
    "    decoder.predict(encoder.get_root_embedding(), len(s2.split()))\n",
    "    print('')\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    for item in decoder.sequence:\n",
    "        print(item.pw, item.pd, item.ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
